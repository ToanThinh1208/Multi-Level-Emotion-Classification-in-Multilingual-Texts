{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting underthesea\n",
      "  Using cached underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from underthesea) (8.1.8)\n",
      "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
      "  Using cached python_crfsuite-0.9.11-cp310-cp310-win_amd64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from underthesea) (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from underthesea) (4.67.1)\n",
      "Collecting requests (from underthesea)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from underthesea) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from underthesea) (1.6.1)\n",
      "Collecting PyYAML (from underthesea)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting underthesea-core==1.0.4 (from underthesea)\n",
      "  Using cached underthesea_core-1.0.4-cp310-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from nltk->underthesea) (2024.11.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->underthesea)\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->underthesea)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->underthesea)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->underthesea)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from scikit-learn->underthesea) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from scikit-learn->underthesea) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\thinh.laptop-gcu8t0aj\\.conda\\envs\\lugak1\\lib\\site-packages (from scikit-learn->underthesea) (3.5.0)\n",
      "Using cached underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n",
      "Using cached underthesea_core-1.0.4-cp310-none-win_amd64.whl (552 kB)\n",
      "Using cached python_crfsuite-0.9.11-cp310-cp310-win_amd64.whl (301 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: underthesea-core, urllib3, PyYAML, python-crfsuite, idna, charset-normalizer, certifi, requests, underthesea\n",
      "Successfully installed PyYAML-6.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 python-crfsuite-0.9.11 requests-2.32.3 underthesea-6.8.4 underthesea-core-1.0.4 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Thinh.LAPTOP-\n",
      "[nltk_data]     GCU8T0AJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Thinh.LAPTOP-\n",
      "[nltk_data]     GCU8T0AJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Làm sạch hoàn tất. File được lưu tại: ./dataset/Amazon_Product_Review_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from underthesea import word_tokenize as vn_word_tokenize, text_normalize\n",
    "\n",
    "# Tải dữ liệu cần thiết\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Hàm làm sạch văn bản\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Loại bỏ thẻ HTML\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Chuyển văn bản về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # Xóa ký tự đặc biệt, số và dấu câu (chỉ giữ lại chữ cái và khoảng trắng)\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-ỹ\\s]\", \"\", text)\n",
    "\n",
    "    # Tokenization: phân tách từ cho cả tiếng Anh và tiếng Việt\n",
    "    tokens_en = word_tokenize(text)  # Tiếng Anh\n",
    "    tokens_vn = vn_word_tokenize(text)  # Tiếng Việt\n",
    "\n",
    "    # Kết hợp cả hai kết quả, giữ nguyên stopwords\n",
    "    clean_tokens = list(set(tokens_en + tokens_vn))\n",
    "\n",
    "    # Ghép lại thành chuỗi\n",
    "    return \" \".join(clean_tokens)\n",
    "\n",
    "# Đọc dữ liệu\n",
    "file_path = \"./dataset/Amazon_Product_Review_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Kiểm tra nếu cột review_body tồn tại\n",
    "text_column = \"review_body\"\n",
    "if text_column in df.columns:\n",
    "    df[text_column] = df[text_column].astype(str).apply(clean_text)\n",
    "    df[text_column] = df[text_column].fillna('')  # Xóa NaN\n",
    "\n",
    "text_column = \"review_headline\"\n",
    "if text_column in df.columns:\n",
    "    df[text_column] = df[text_column].astype(str).apply(clean_text)\n",
    "    df[text_column] = df[text_column].fillna('')  # Xóa NaN\n",
    "# Lưu dữ liệu đã làm sạch\n",
    "cleaned_file_path = \"./dataset/Amazon_Product_Review_cleaned.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Làm sạch hoàn tất. File được lưu tại:\", cleaned_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
